# TokenStudio - Custom Tokenizer

A professional tokenizer web application built with Next.js 15 that provides real-time text tokenization with interactive visualization, similar to tiktoken.com.

## âœ¨ Features

- Real-time Tokenization â€” instant encoding/decoding as you type
- Multi-Model Support â€” GPT-4o, GPT-4, GPT-3.5-turbo, and more OpenAI models
- Interactive Visualization â€” color-coded token breakdown with hover details
- Cost Analysis â€” real-time API cost estimation for OpenAI usage
- Sample Text Library â€” pre-loaded examples for quick testing
- Professional UI â€” clean, responsive design with smooth animations

## ðŸš€ Quick Start

```bash
# Clone and install
git clone https://github.com/yourusername/tokenstudio-custom-tokenizer.git
cd tokenstudio-custom-tokenizer
npm install

# Run development server
npm run dev

# Visit
# http://localhost:3000
```

## ðŸ“¸ Application Preview

Place actual images into public/ and keep these markdown links as-is. The app will load them from /images/... at runtime.

- Main Interface  
  ![TokenStudio Main Interface](/images/main-interface.png)
  
- Visualization  
  ![Token Visualization](/images/token-visualization.png)
  
### Basic Text Tokenization

Input:

```text
"Hello, world! How are you today?"
```

Output:

- Token Count: 8 tokens
- Token IDs: [9906][1917][2650][3432]
- Estimated Cost: $0.00024 (GPT-3.5-turbo)

### Programming Code Example

Input:

```js
function fibonacci(n) {
  if (n <= 1) return n;
  return fibonacci(n-1) + fibonacci(n-2);
}
```

Results:

- GPT-4o: 32 tokens â†’ $0.00096
- GPT-3.5: 35 tokens â†’ $0.00105
- Best Model: GPT-4o (8.6% more efficient)

### Model Efficiency Comparison

| Model         | Tokens   | Cost      | Efficiency |
|---------------|----------|-----------|------------|
| GPT-4o        | 6 tokens | $0.00018  | â­ Best     |
| GPT-4         | 7 tokens | $0.00021  | Good       |
| GPT-3.5-turbo | 8 tokens | $0.00012  | Cheapest   |

## ðŸ› ï¸ Tech Stack

- Next.js 15 (App Router) + JavaScript
- Tailwind CSS + shadcn/ui components
- js-tiktoken for OpenAI-compatible tokenization
- Lucide React icons

## ðŸ“± How to Use

1. Select Model â€” choose from GPT-4o, GPT-4, or GPT-3.5-turbo.
2. Enter Text â€” type or select from sample texts.
3. View Results â€” see real-time token breakdown and statistics.
4. Analyze Tokens â€” hover over colored tokens for details.
5. Copy Results â€” export token arrays for your applications.

## ðŸ“Š Key Features

- Token Count â€” exact number of tokens for API planning
- Cost Estimation â€” calculate OpenAI API costs before making calls
- Token Visualization â€” see exactly how text is broken down
- Model Comparison â€” compare efficiency across different models
- Roundtrip Verification â€” ensure perfect encode/decode accuracy

## ðŸ“¦ Project Structure

```text
src/
â”œâ”€â”€ app/                         # Next.js 15 App Router
â”‚   â”œâ”€â”€ layout.js                # Root layout
â”‚   â”œâ”€â”€ page.js                  # Main entry point
â”‚   â””â”€â”€ globals.css              # Global styles
â”œâ”€â”€ components/                  # React components
â”‚   â”œâ”€â”€ ui/                      # shadcn/ui components
â”‚   â”œâ”€â”€ header.js                # Application header
â”‚   â”œâ”€â”€ tokenizer-interface.js   # Main interface
â”‚   â””â”€â”€ token-visualizer.js      # Token visualization
â””â”€â”€ lib/                         # Core logic
    â”œâ”€â”€ tiktoken-wrapper.js      # Tokenizer integration
    â””â”€â”€ sample-data.js           # Sample texts & models
```

## ðŸš€ Deployment

### Vercel (Recommended)

```bash
npm run build
# Deploy to vercel.com by connecting your GitHub repository
```

### Local Production

```bash
npm run build
npm start
```

## ðŸ”§ Core Components

- TokenizerInterface â€” main app with real-time processing
- TokenVisualizer â€” interactive color-coded token display
- ModelSelector â€” switch between OpenAI models
- StatsDashboard â€” token counts, costs, and efficiency metrics

## ðŸ“ˆ Features Implemented

- ENCODE/DECODE â€” bidirectional token conversion  
- Vocabulary Learning â€” built-in BPE algorithm  
- Special Tokens â€” handles unknown and special markers  
- Real-time Processing â€” instant results as you type  
- Professional UI â€” modern, responsive design  

***

Built with Next.js 15 for a fast, modern tokenization experience.
